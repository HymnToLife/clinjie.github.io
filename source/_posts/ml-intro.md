title: ML相关术语
date: 2017-02-28 11:00:13
toc: true
tags: ML
categories: ML
---

机器学习：研究如何通过计算的手段，利用经验来改善系统自身的性能。

计算机系统中，“经验”通常以“data”形式存在，所以机器学习从数据中产生模型（model）的算法，称为学习算法。模型，即从数据中学到的结果。

通过向学习算法中输入已有的数据，算法产生模型，面对新的case时，模型就可以通过case的特性进行判断。

一组数据的集合称为数据集，其中每条记录是关于一个事件或对象的描述，称为"示例"（instance）或者"样本"（sample）。

描述中不同的性质称为属性。通过属性做成的坐标轴称为属性空间、样本空间或者输入空间。
<!--more-->
在属性空间中，每个描述都与一个点对应，所以我们也把一个描述称作是"特征向量"。

从数据中学得模型的过程称为"学习"或者"训练"，这个过程通过执行某个学习算法完成。训练样本组成的集合称为"训练集"

训练样例的结果信息称为“样例”。 如果需要预测的是离散值，例如（1、2、3、4、5），称为分类预测（classification）。特别的，离散值只有两个的情况称为二分类（binary classification），多个离散值称为多分类。如果需要预测的结果范围是一个连续值，或者是不可数结果，此时的学习任务称为回归任务（regression）。

聚类：将训练集中的西瓜分为若干组，每组称为一个"簇"；簇是自动形成的，对应一些潜在的概念划分，这些潜在的概念划分我们事先不知道，而且学习过程中使用的训练样本通常不用有标记信息（提前设定的结果）


训练样本有标记信息的学习任务称为监督学习（supervised learning），否则称为无监督学习（unsupervised learning）。分类回归是监督学习的代表，聚类（clustering）是后者的代表。

泛化（generalization）：学得模型适用于新样本的能力。


# 归纳偏好 #
由于训练样本的数据量无法代表整个样本空间，可能会存在这种情况：预测样本可以匹配到多个训练样本结果，而这些不同的训练结果有不同的输出。表现为分类中属不同类。

此时无法通过匹配的手段确定到底使用哪个训练样本结果，学习算法的"偏好"就很重要了。通过提前设置的偏好，在遇到这种情况时候，算法会自动根据偏好选择合适的预测结果。称为"归纳偏好"（inductive bias）

## 奥卡姆剃刀 ##

奥卡姆剃刀是一种常用的、自然科学研究中最基本的原则，即"若有多个假设与观察一直，则选择最简单的那个"。

如无必要，勿增实体

## NFL定理 ##

所有问题同等重要的前提下，任意两个学习算法的期望性能是相同的。就是说误差率是相同的。NFL定理的重要定义是要我们认识到，脱离具体问题，空泛的谈论"什么学习算法更好没有意义"。学习算法自身的归纳偏好与问题是否匹配，往往起到决定性作用。


# 历史进程 #

## 机械学习 ##

将所有样例记住，并在需要预测的时候拿出，实际上是一种检索方法，没有涉及到学习。

## 符号主义学习 ##

这个阶段，代表的学习方法有决策树和基于逻辑学习。

## 基于连接主义 ##

主要是神经网络学习，BP学习方法大放异彩。

## 基于统计的学习 ##

SVM支持向量机的提出

# DM与ML #

数据挖掘（Data Mining）是从海量的数据中发掘知识，主要包括两个支撑技术：数据库管理和机器学习。

数据库领域为数据挖掘提供数据管理技术，而ML和统计学为DM提供数据分析技术。
