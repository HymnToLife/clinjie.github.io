title: 伯乐对象年龄爬虫
date: 2016-02-28 22:23:35
tags: 
- Python
- Requests
- re
categories: Python
---

![](http://7xowaa.com1.z0.glb.clouddn.com/duixiang.jpg)

接着上一篇[相关文章](\2016\02\27\伯乐爬虫 "博客爬虫-身高")，还是说伯乐在线这个网站上有一个面向对象栏目。这次呢，不看妹子要求男生的身高问题，来瞧一瞧妹子在这个栏目上发帖子寻找soul mate的时间：）

<!--more-->   

实际上呢，网页信息是跟上次的一模一样，也就是说完全可以将上篇文章的网页代码保存在本地，设置好间隔符，通过不同的过滤规则获取相应的数据。


下面是我的代码：  

```python
import requests
import re
import os
import sys

import time
from bs4 import BeautifulSoup

urlsFile = os.path.join(sys.path[0],'urls.txt')
# 保存帖子url的本地路径的字符串,os.path.join()知识提供文件路径拼接功能 如果想要创建文件 则使用os.mkdir(path)
infoNum = 0 #有效信息的总条数
num = 0   #包含敏感信息的总条数


def getUrls():
    if os.path.exists(urlsFile) :
        return getUrlsFromFile()
    urlList = list()
    url='http://date.jobbole.com/page/1/?sort=latest'
    while url:
        html = requests.get(url)
        pattern='href=\"(.*?)\">.*?</a><label class=\"hide-on-480 small-domain-url\"></label>'
        urlList += re.findall(pattern,html.text)
        tem=(re.findall('<li id=\"pagination-next-page\"><a href=\"(.*?)\"',html.text))
        if len(tem)>0:url=tem[0]
        else:url=None
    saveUrls(urlList)
    return urlList



def getUrlsFromFile():
    urlList = list()
    f = open(urlsFile,'r')
    for line in f.readlines():
        #需要注意的是，智力读取的是包括换行符的字符串，因为在写入文件时已经直接写入了换行符，这里将文件按行分开
        #想要获取纯正的源数据可以使用str.strip()函数
        urlList.append(line)
    f.close()
    return urlList

def saveUrls(urlList):
    with open(urlsFile, "w",encoding='utf-8') as fp:
        fp.write("%s" % '\n'.join(urlList))

#查询该帖子下的内容
def viewUrl(url):
    result = ""
    html = requests.get(url)
    info = re.findall('出生年月：(.*?)<br />',html.text)
    print(url.strip())
    if len(info):
        if len(info)>1:
            if len(info[0])>len(info[1]) and info[1]!='':info[0]=info[1]
        if info[0]!='':
            result = info[0]
            isAboutA(result)
    f.close()

#是否有涉及身高的敏感信息
def isAboutA(info):
    global num
    keys=['(\d{4})','(\d{4}\.\d{2})','(\d{2}\.\d*)','(\d{2})年']
    f=open('infoA.txt','a')
    for p in keys:
        r = re.findall(p,info)
        if(len(r)):
            num = num + 1
            f.write(str(r[0])+"\n")
            print(info)
            print(r[0])
            break
    f.close()

def getAvarge():
    numList=list()
    f = open("infoA.txt","r")
    for line in f.readlines():
        line=line.strip()
        if line!='':
            #去除小数点
            if line.find('.')!=-1:
                line=(line.split('.'))[0]
            if len(line)==2:
                line='19'+line
            num = int(line)
            numList.append(num)
    result=0.0
    for num in numList:
        result+=num
    return '%.2f' % (2016-result/len(numList))

f=open('infoA.txt','w')
f.close()
urlList = getUrls()
num = 0
for i in range(0,len(urlList)):
    print('第'+str(i+1)+'个begin:')
    viewUrl(urlList[i])
    print('进度 %.2f\n' % ((i+1)/len(urlList)))
    time.sleep(0.1)
print(len(urlList))
print(num)

print('结果为 %.2f' % getAvarge())
```

`结果为27.44`

通过爬虫信息可以看出，27岁是个中间值，我也没有具体的研究年龄分布问题，后续等我有更科学的方法、数据量之后再来研究~